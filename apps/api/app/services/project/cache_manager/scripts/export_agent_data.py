#!/usr/bin/env python3
"""
æ™ºèƒ½ä½“æ•°æ®å¯¼å‡ºè„šæœ¬

æ ¹æ®æ™ºèƒ½ä½“ç±»å‹å¯¼å‡ºæ‰€éœ€çš„æ•°æ®èµ„æºåˆ°æœ¬åœ°ç¼“å­˜ã€‚

æ”¯æŒçš„æ™ºèƒ½ä½“ç±»å‹:
    - data_analysis: æ•°æ®åˆ†ææ™ºèƒ½ä½“ï¼ˆæ•°æ®è¡¨ + BIæŠ¥è¡¨ï¼‰
    - fin_data_analysis: é‡‘èæ•°æ®åˆ†ææ™ºèƒ½ä½“ï¼ˆé‡‘èæŒ‡æ ‡è§†å›¾è¡¨ï¼‰

æ•°æ®æ¥æº:
    - æ•°æ®è¡¨/æŠ¥è¡¨/é‡‘èè§†å›¾è¡¨: é€šè¿‡HTTPS APIè·å–ï¼ˆæ”¯æŒå¼€å‘/ç”Ÿäº§ç¯å¢ƒè‡ªåŠ¨åˆ‡æ¢ï¼‰

ç”¨æ³•:
    python3 export_agent_data.py [--agent-type TYPE] [OPTIONS]

é€‰é¡¹:
    --agent-type TYPE           æ™ºèƒ½ä½“ç±»å‹ (å¿…éœ€)
    --business-lines BL1,BL2    ä¸šåŠ¡çº¿è¿‡æ»¤ (å¯é€‰)
    --query KEYWORD            æŸ¥è¯¢å…³é”®å­— (å¯é€‰)
    --batch-size SIZE          æ‰¹å¤„ç†å¤§å° (å¯é€‰)
    --dry-run                  é¢„è§ˆæ¨¡å¼ï¼Œä¸å†™å…¥æ–‡ä»¶
    --verbose                  è¯¦ç»†è¾“å‡º

ç¤ºä¾‹:
    # å¯¼å‡ºæ•°æ®åˆ†ææ™ºèƒ½ä½“çš„æ‰€æœ‰æ•°æ®
    python3 export_agent_data.py --agent-type data_analysis

    # å¯¼å‡ºé‡‘èæ•°æ®åˆ†ææ™ºèƒ½ä½“çš„æ‰€æœ‰æ•°æ®
    python3 export_agent_data.py --agent-type fin_data_analysis

    # ä»…å¯¼å‡ºæŒ‡å®šé¢†åŸŸçš„é‡‘èè§†å›¾è¡¨
    python3 export_agent_data.py --agent-type fin_data_analysis --domains stock,fund

    # ä»…å¯¼å‡ºiwcä¸šåŠ¡çº¿çš„æ•°æ®
    python3 export_agent_data.py --agent-type data_analysis --business-lines iwc

    # é¢„è§ˆæ¨¡å¼
    python3 export_agent_data.py --agent-type data_analysis --dry-run

    # è¯¦ç»†è¾“å‡º
    python3 export_agent_data.py --agent-type data_analysis --verbose
"""
import sys
import asyncio
import logging
import argparse
from pathlib import Path
from typing import List, Optional

# åŠ¨æ€æŸ¥æ‰¾å¹¶æ·»åŠ apps/apiç›®å½•åˆ°sys.path
def find_api_root():
    """å‘ä¸ŠæŸ¥æ‰¾apps/apiç›®å½•"""
    current = Path(__file__).resolve().parent
    while current.parent != current:  # é˜²æ­¢åˆ°è¾¾æ ¹ç›®å½•
        # æ£€æŸ¥æ˜¯å¦æ˜¯apiç›®å½•ï¼ˆåŒ…å«appå­ç›®å½•ï¼‰
        if (current / "app").exists() and (current / "app").is_dir():
            # éªŒè¯è¿™æ˜¯æ­£ç¡®çš„apiç›®å½•ï¼ˆåŒ…å«cache_managerï¼‰
            if (current / "app" / "services" / "project" / "cache_manager").exists():
                return current
        current = current.parent
    raise RuntimeError("æ— æ³•æ‰¾åˆ°apps/apiç›®å½•ï¼Œè¯·ç¡®ä¿è„šæœ¬åœ¨æ­£ç¡®çš„é¡¹ç›®ç»“æ„ä¸­è¿è¡Œ")

api_root = find_api_root()
sys.path.insert(0, str(api_root))

# åŠ è½½ .env æ–‡ä»¶ï¼ˆå¿…éœ€ï¼šPython è„šæœ¬ä¸ä¼šè‡ªåŠ¨è¯»å– .envï¼‰
# å¿…é¡»åœ¨å¯¼å…¥å…¶ä»–æ¨¡å—ä¹‹å‰åŠ è½½ï¼Œç¡®ä¿ ConfigManager å’Œ Settings èƒ½è¯»å–åˆ°ç¯å¢ƒå˜é‡
from dotenv import load_dotenv
project_root = api_root.parent.parent  # ä» apps/api å‘ä¸Šä¸¤çº§åˆ°é¡¹ç›®æ ¹ç›®å½•
env_file = project_root / ".env"
load_dotenv(env_file)  # å³ä½¿æ–‡ä»¶ä¸å­˜åœ¨ä¹Ÿä¸ä¼šæŠ¥é”™ï¼Œload_dotenv ä¼šé™é»˜å¤„ç†

from app.services.project.cache_manager.config.config_manager import ConfigManager
from app.services.project.cache_manager.config.constants import get_agent_type_config
from app.services.project.cache_manager.exporters.data_table_exporter import DataTableExporter
from app.services.project.cache_manager.exporters.report_exporter import ReportExporter
from app.services.project.cache_manager.exporters.fin_view_exporter import FinViewExporter


def setup_logging(verbose: bool = False):
    """è®¾ç½®æ—¥å¿—"""
    level = logging.DEBUG if verbose else logging.INFO
    logging.basicConfig(
        level=level,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        datefmt='%Y-%m-%d %H:%M:%S'
    )


async def export_data_analysis(
    config: ConfigManager,
    agent_type: str,
    business_lines: Optional[List[str]] = None,
    dry_run: bool = False,
    verbose: bool = False,
    query: Optional[str] = None,
    batch_size: int = 10
) -> bool:
    """
    å¯¼å‡ºæ•°æ®åˆ†ææ™ºèƒ½ä½“çš„æ‰€æœ‰é¡¹ç›®åˆå§‹åŒ–æ•°æ®

    åŒ…æ‹¬ï¼š
    - æ•°æ®è¡¨ï¼ˆPHYSICALï¼‰
    - BIæŠ¥è¡¨ï¼ˆREPORTï¼‰

    Args:
        config: é…ç½®ç®¡ç†å™¨
        agent_type: æ™ºèƒ½ä½“ç±»å‹
        business_lines: ä¸šåŠ¡çº¿è¿‡æ»¤
        dry_run: æ˜¯å¦é¢„è§ˆæ¨¡å¼
        verbose: æ˜¯å¦è¯¦ç»†è¾“å‡º
        query: æŸ¥è¯¢å…³é”®å­—
        batch_size: æ‰¹å¤„ç†å¤§å°

    Returns:
        æ˜¯å¦å…¨éƒ¨æˆåŠŸ
    """
    logger = logging.getLogger(__name__)
    logger.info("=" * 80)
    logger.info("å¼€å§‹å¯¼å‡ºæ•°æ®åˆ†ææ™ºèƒ½ä½“é¡¹ç›®åˆå§‹åŒ–æ•°æ®")
    logger.info("=" * 80)

    # åˆ é™¤æ—§çš„ agent_type ç›®å½•
    if not dry_run:
        import shutil
        agent_output_dir = config.get_output_dir(agent_type)
        if agent_output_dir.exists():
            logger.info(f"\nğŸ—‘ï¸  åˆ é™¤æ—§çš„å¯¼å‡ºç›®å½•: {agent_output_dir}")
            try:
                shutil.rmtree(agent_output_dir)
                logger.info("âœ… æ—§ç›®å½•åˆ é™¤æˆåŠŸ")
            except Exception as e:
                logger.error(f"âŒ åˆ é™¤æ—§ç›®å½•å¤±è´¥: {str(e)}")
                return False

    all_success = True

    # 1. å¯¼å‡ºæ•°æ®è¡¨ï¼ˆPHYSICALï¼‰
    logger.info("\nğŸ“Š [1/2] å¯¼å‡ºæ•°æ®è¡¨...")
    logger.info("-" * 80)
    try:
        table_exporter = DataTableExporter(config, agent_type)
        success = await table_exporter.export(
            business_lines=business_lines,
            dry_run=dry_run,
            verbose=verbose,
            table_type='PHYSICAL',
            query=query,
            batch_size=batch_size
        )
        if not success:
            logger.error("âŒ æ•°æ®è¡¨å¯¼å‡ºå¤±è´¥")
            all_success = False
        else:
            logger.info("âœ… æ•°æ®è¡¨å¯¼å‡ºå®Œæˆ")
    except Exception as e:
        logger.error(f"âŒ æ•°æ®è¡¨å¯¼å‡ºå¼‚å¸¸: {str(e)}", exc_info=True)
        all_success = False

    # 2. å¯¼å‡ºBIæŠ¥è¡¨ï¼ˆREPORTï¼‰
    logger.info("\nğŸ“ˆ [2/2] å¯¼å‡ºBIæŠ¥è¡¨...")
    logger.info("-" * 80)
    try:
        report_exporter = ReportExporter(config, agent_type)
        success = await report_exporter.export(
            business_lines=business_lines,
            dry_run=dry_run,
            verbose=verbose,
            query=query
        )
        if not success:
            logger.error("âŒ BIæŠ¥è¡¨å¯¼å‡ºå¤±è´¥")
            all_success = False
        else:
            logger.info("âœ… BIæŠ¥è¡¨å¯¼å‡ºå®Œæˆ")
    except Exception as e:
        logger.error(f"âŒ BIæŠ¥è¡¨å¯¼å‡ºå¼‚å¸¸: {str(e)}", exc_info=True)
        all_success = False

    return all_success


async def export_fin_data_analysis(
    config: ConfigManager,
    agent_type: str,
    domains: Optional[List[str]] = None,
    dry_run: bool = False,
    verbose: bool = False,
    page_size: int = 100
) -> bool:
    """
    å¯¼å‡ºé‡‘èæ•°æ®åˆ†ææ™ºèƒ½ä½“çš„é¡¹ç›®åˆå§‹åŒ–æ•°æ®

    åŒ…æ‹¬ï¼š
    - é‡‘èæŒ‡æ ‡è§†å›¾è¡¨

    Args:
        config: é…ç½®ç®¡ç†å™¨
        agent_type: æ™ºèƒ½ä½“ç±»å‹
        domains: Domainè¿‡æ»¤ï¼ˆä½¿ç”¨ç®€ç§°ï¼Œå¦‚ï¼šstock, fundï¼‰
        dry_run: æ˜¯å¦é¢„è§ˆæ¨¡å¼
        verbose: æ˜¯å¦è¯¦ç»†è¾“å‡º
        page_size: æ¯é¡µå¤§å°

    Returns:
        æ˜¯å¦å…¨éƒ¨æˆåŠŸ
    """
    logger = logging.getLogger(__name__)
    logger.info("=" * 80)
    logger.info("å¼€å§‹å¯¼å‡ºé‡‘èæ•°æ®åˆ†ææ™ºèƒ½ä½“é¡¹ç›®åˆå§‹åŒ–æ•°æ®")
    logger.info("=" * 80)

    # åˆ é™¤æ—§çš„ agent_type ç›®å½•
    if not dry_run:
        import shutil
        agent_output_dir = config.get_output_dir(agent_type)
        if agent_output_dir.exists():
            logger.info(f"\nğŸ—‘ï¸  åˆ é™¤æ—§çš„å¯¼å‡ºç›®å½•: {agent_output_dir}")
            try:
                shutil.rmtree(agent_output_dir)
                logger.info("âœ… æ—§ç›®å½•åˆ é™¤æˆåŠŸ")
            except Exception as e:
                logger.error(f"âŒ åˆ é™¤æ—§ç›®å½•å¤±è´¥: {str(e)}")
                return False

    all_success = True

    # å¯¼å‡ºé‡‘èæŒ‡æ ‡è§†å›¾è¡¨
    logger.info("\nğŸ’° [1/1] å¯¼å‡ºé‡‘èæŒ‡æ ‡è§†å›¾è¡¨...")
    logger.info("-" * 80)
    try:
        fin_view_exporter = FinViewExporter(config, agent_type)
        success = await fin_view_exporter.export(
            domains=domains,
            dry_run=dry_run,
            verbose=verbose,
            page_size=page_size
        )
        if not success:
            logger.error("âŒ é‡‘èæŒ‡æ ‡è§†å›¾è¡¨å¯¼å‡ºå¤±è´¥")
            all_success = False
        else:
            logger.info("âœ… é‡‘èæŒ‡æ ‡è§†å›¾è¡¨å¯¼å‡ºå®Œæˆ")
    except Exception as e:
        logger.error(f"âŒ é‡‘èæŒ‡æ ‡è§†å›¾è¡¨å¯¼å‡ºå¼‚å¸¸: {str(e)}", exc_info=True)
        all_success = False

    return all_success


async def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(
        description='å¯¼å‡ºæŒ‡å®šæ™ºèƒ½ä½“çš„æ‰€æœ‰é¡¹ç›®åˆå§‹åŒ–æ•°æ®åˆ°æœ¬åœ°YAMLæ–‡ä»¶',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
æ™ºèƒ½ä½“ç±»å‹è¯´æ˜:
  data_analysis      - æ•°æ®åˆ†ææ™ºèƒ½ä½“ï¼ˆåŒ…å«ï¼šæ•°æ®è¡¨ã€BIæŠ¥è¡¨ï¼‰
  fin_data_analysis  - é‡‘èæ•°æ®åˆ†ææ™ºèƒ½ä½“ï¼ˆåŒ…å«ï¼šé‡‘èæŒ‡æ ‡è§†å›¾è¡¨ï¼‰

ç¤ºä¾‹:
  # å¯¼å‡ºæ•°æ®åˆ†ææ™ºèƒ½ä½“çš„é¡¹ç›®åˆå§‹åŒ–æ•°æ®
  %(prog)s --agent-type data_analysis

  # å¯¼å‡ºé‡‘èæ•°æ®åˆ†ææ™ºèƒ½ä½“çš„æ‰€æœ‰è§†å›¾è¡¨
  %(prog)s --agent-type fin_data_analysis

  # å¯¼å‡ºé‡‘èæ•°æ®åˆ†ææ™ºèƒ½ä½“çš„æŒ‡å®šé¢†åŸŸè§†å›¾è¡¨
  %(prog)s --agent-type fin_data_analysis --domains stock,fund

  # é¢„è§ˆæ¨¡å¼
  %(prog)s --agent-type data_analysis --dry-run
        """
    )
    parser.add_argument(
        '--agent-type',
        required=True,
        choices=['data_analysis', 'fin_data_analysis'],
        help='æ™ºèƒ½ä½“ç±»å‹'
    )
    parser.add_argument(
        '--business-lines',
        help='ä¸šåŠ¡çº¿è¿‡æ»¤ï¼Œå¤šä¸ªç”¨é€—å·åˆ†éš”ï¼ˆå¦‚ï¼šiwc,cotï¼‰ã€‚ä»…é€‚ç”¨äºdata_analysis'
    )
    parser.add_argument(
        '--domains',
        help='Domainè¿‡æ»¤ï¼Œå¤šä¸ªç”¨é€—å·åˆ†éš”ï¼ˆå¦‚ï¼šstock,fund,macroï¼‰ã€‚ä»…é€‚ç”¨äºfin_data_analysis'
    )
    parser.add_argument(
        '--query',
        help='æŸ¥è¯¢å…³é”®å­—ã€‚ä»…é€‚ç”¨äºdata_analysisæ™ºèƒ½ä½“ç±»å‹'
    )
    parser.add_argument(
        '--page-size',
        type=int,
        help='æ¯é¡µå¤§å°ã€‚ä»…é€‚ç”¨äºfin_data_analysisï¼ˆé»˜è®¤100ï¼‰'
    )
    parser.add_argument(
        '--dry-run',
        action='store_true',
        help='é¢„è§ˆæ¨¡å¼ï¼Œä¸å®é™…å†™å…¥æ–‡ä»¶'
    )
    parser.add_argument(
        '--verbose',
        action='store_true',
        help='è¯¦ç»†è¾“å‡º'
    )
    parser.add_argument(
        '--batch-size',
        type=int,
        help='æ‰¹å¤„ç†å¤§å°ï¼ˆdata_analysisé»˜è®¤10ï¼Œdata_developé»˜è®¤50ï¼‰'
    )

    args = parser.parse_args()

    # è®¾ç½®æ—¥å¿—
    setup_logging(args.verbose)
    logger = logging.getLogger(__name__)

    try:
        # éªŒè¯æ™ºèƒ½ä½“ç±»å‹
        agent_type_config = get_agent_type_config(args.agent_type)

        logger.info(f"\n{'=' * 80}")
        logger.info(f"æ™ºèƒ½ä½“ç±»å‹: {args.agent_type}")
        logger.info(f"æè¿°: {agent_type_config['description']}")
        logger.info(f"åŒ…å«æ•°æ®ç±»å‹: {', '.join(agent_type_config['data_types'])}")
        logger.info(f"{'=' * 80}\n")

        # è§£æä¸šåŠ¡çº¿è¿‡æ»¤
        business_lines = None
        if args.business_lines:
            business_lines = [bl.strip() for bl in args.business_lines.split(',')]
            logger.info(f"ä¸šåŠ¡çº¿è¿‡æ»¤: {', '.join(business_lines)}\n")

        # åˆå§‹åŒ–é…ç½®ç®¡ç†å™¨
        config = ConfigManager()

        # éªŒè¯é…ç½®
        is_valid, error_msg = config.validate_config()
        if not is_valid:
            logger.error(f"é…ç½®éªŒè¯å¤±è´¥: {error_msg}")
            sys.exit(1)

        # æ ¹æ®æ™ºèƒ½ä½“ç±»å‹æ‰§è¡Œä¸åŒçš„å¯¼å‡ºé€»è¾‘
        success = False

        if args.agent_type == 'data_analysis':
            # ç¡®å®šæ‰¹å¤„ç†å¤§å°
            batch_size = args.batch_size if args.batch_size is not None else 10

            # domainså‚æ•°å¯¹data_analysisæ— æ•ˆ
            if args.domains:
                logger.warning("âš ï¸  --domains å‚æ•°å¯¹ data_analysis æ™ºèƒ½ä½“ç±»å‹æ— æ•ˆï¼Œå°†è¢«å¿½ç•¥")

            success = await export_data_analysis(
                config=config,
                agent_type=args.agent_type,
                business_lines=business_lines,
                dry_run=args.dry_run,
                verbose=args.verbose,
                query=args.query,
                batch_size=batch_size
            )
        elif args.agent_type == 'fin_data_analysis':
            # business-lineså’Œqueryå‚æ•°å¯¹fin_data_analysisæ— æ•ˆ
            if args.business_lines:
                logger.warning("âš ï¸  --business-lines å‚æ•°å¯¹ fin_data_analysis æ™ºèƒ½ä½“ç±»å‹æ— æ•ˆï¼Œå°†è¢«å¿½ç•¥")
            if args.query:
                logger.warning("âš ï¸  --query å‚æ•°å¯¹ fin_data_analysis æ™ºèƒ½ä½“ç±»å‹æ— æ•ˆï¼Œå°†è¢«å¿½ç•¥")

            # è§£ædomainsè¿‡æ»¤
            domains = None
            if args.domains:
                domains = [d.strip() for d in args.domains.split(',')]
                logger.info(f"Domainè¿‡æ»¤: {', '.join(domains)}\n")

            # ç¡®å®šæ¯é¡µå¤§å°
            page_size = args.page_size if args.page_size is not None else 100

            # éªŒè¯ FIN_VIEW_BASE_URL ç¯å¢ƒå˜é‡
            import os
            fin_view_base_url = os.getenv('FIN_VIEW_BASE_URL')
            if not fin_view_base_url:
                logger.error("âŒ ç¯å¢ƒå˜é‡ FIN_VIEW_BASE_URL æœªé…ç½®ï¼Œè¯·åœ¨.envæ–‡ä»¶ä¸­é…ç½®")
                logger.error("ç¤ºä¾‹ï¼šFIN_VIEW_BASE_URL=https://indexmap.myhexin.com/bfe")
                sys.exit(1)
            logger.info(f"FIN_VIEW_BASE_URL: {fin_view_base_url}\n")

            success = await export_fin_data_analysis(
                config=config,
                agent_type=args.agent_type,
                domains=domains,
                dry_run=args.dry_run,
                verbose=args.verbose,
                page_size=page_size
            )

        # è¾“å‡ºæœ€ç»ˆç»“æœ
        logger.info("\n" + "=" * 80)
        if success:
            logger.info("âœ… æ™ºèƒ½ä½“é¡¹ç›®åˆå§‹åŒ–æ•°æ®å¯¼å‡ºä»»åŠ¡å…¨éƒ¨å®Œæˆ")
            logger.info("=" * 80)
            sys.exit(0)
        else:
            logger.error("âŒ éƒ¨åˆ†å¯¼å‡ºä»»åŠ¡å¤±è´¥ï¼Œè¯·æ£€æŸ¥ä¸Šè¿°é”™è¯¯ä¿¡æ¯")
            logger.info("=" * 80)
            sys.exit(1)

    except KeyboardInterrupt:
        logger.info("\nç”¨æˆ·ä¸­æ–­å¯¼å‡º")
        sys.exit(130)
    except Exception as e:
        logger.error(f"\nå¯¼å‡ºè¿‡ç¨‹å‘ç”Ÿå¼‚å¸¸: {str(e)}", exc_info=True)
        sys.exit(1)


if __name__ == "__main__":
    asyncio.run(main())
