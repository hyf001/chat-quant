"""
FinView Exporter - é‡‘èæŒ‡æ ‡è§†å›¾è¡¨å¯¼å‡ºå™¨
"""
import asyncio
import logging
import os
from datetime import datetime
from typing import List, Optional, Dict, Any
from pathlib import Path

from .base_exporter import BaseExporter
from ..client.fin_view_https_client import FinViewHttpsClient
from ..config.config_manager import ConfigManager
from ..utils.file_manager import FileManager
from ..utils.data_processor import sanitize_filename

logger = logging.getLogger(__name__)


class FinViewExporter(BaseExporter):
    """é‡‘èæŒ‡æ ‡è§†å›¾è¡¨å¯¼å‡ºå™¨"""

    # Domainæ˜ å°„ï¼šåŸå§‹domain -> ç®€ç§°
    DOMAIN_MAPPING = {
        "abs_è‚¡ç¥¨é¢†åŸŸ": "stock",
        "abs_å…¨é‡å€ºåˆ¸é¢†åŸŸ": "zhaiquan",
        "abs_å¯è½¬å€ºé¢†åŸŸ": "conbond",
        "abs_åŒèŠ±é¡ºä¿é™©é¢†åŸŸ": "thsinsurance",
        "abs_å›½é™…ç¾è‚¡é¢†åŸŸ": "intusstock",
        "abs_åŸºé‡‘é¢†åŸŸ": "fund",
        "abs_åŸºé‡‘å…¬å¸é¢†åŸŸ": "fundcompany",
        "abs_åŸºé‡‘ç»ç†é¢†åŸŸ": "fundmanager",
        "abs_å®è§‚é¢†åŸŸ": "macro",
        "abs_å®è§‚é‡‘èé¢†åŸŸ": "macro",
        "abs_å¸‚åœºç¯å¢ƒ": "marketcalendar",
        "abs_å…¨é‡æŒ‡æ•°é¢†åŸŸ": "zhishu",
        "abs_æ–°ä¸‰æ¿é¢†åŸŸ": "threeboard",
        "abs_æœŸæƒé¢†åŸŸ": "options",
        "abs_æœŸè´§é¢†åŸŸ": "futures",
        "abs_æœŸè´§å“ç§é¢†åŸŸ": "futures_product",
        "abs_æ¸¯è‚¡é¢†åŸŸ": "hkstock",
        "abs_ç¾è‚¡é¢†åŸŸ": "usstock",
        "abs_é“¶è¡Œç†è´¢é¢†åŸŸ": "bwmp",
    }

    def __init__(self, config: ConfigManager, agent_type: str = "fin_data_analysis"):
        """
        åˆå§‹åŒ–é‡‘èæŒ‡æ ‡è§†å›¾è¡¨å¯¼å‡ºå™¨

        Args:
            config: é…ç½®ç®¡ç†å™¨
            agent_type: æ™ºèƒ½ä½“ç±»å‹ï¼ˆå›ºå®šä¸º fin_data_analysisï¼‰
        """
        super().__init__(config, agent_type)

        # åˆå§‹åŒ–æ–‡ä»¶ç®¡ç†å™¨
        self.file_manager = FileManager(str(self.output_dir))

        # åˆå§‹åŒ–FinView HTTPå®¢æˆ·ç«¯
        self.https_client = FinViewHttpsClient()

    async def export(self,
                    domains: Optional[List[str]] = None,
                    dry_run: bool = False,
                    verbose: bool = False,
                    page_size: int = 100,
                    use_atomic_replace: bool = True) -> bool:
        """
        å¯¼å‡ºé‡‘èæŒ‡æ ‡è§†å›¾è¡¨

        Args:
            domains: Domainè¿‡æ»¤ï¼ˆç®€ç§°åˆ—è¡¨ï¼Œå¦‚ ["stock", "fund"]ï¼‰
            dry_run: æ˜¯å¦ä¸ºé¢„è§ˆæ¨¡å¼
            verbose: æ˜¯å¦è¯¦ç»†è¾“å‡º
            page_size: æ¯é¡µå¤§å°
            use_atomic_replace: æ˜¯å¦ä½¿ç”¨åŸå­æ€§æ›¿æ¢ï¼ˆé»˜è®¤Trueï¼‰

        Returns:
            æ˜¯å¦æˆåŠŸ
        """
        start_time = datetime.now()

        try:
            logger.info("ğŸš€ å¼€å§‹å¯¼å‡ºé‡‘èæŒ‡æ ‡è§†å›¾è¡¨...")

            if dry_run:
                logger.info("ğŸ“‹ é¢„è§ˆæ¨¡å¼ - ä¸ä¼šå®é™…å†™å…¥æ–‡ä»¶")

            if use_atomic_replace and not dry_run:
                logger.info("ğŸ”„ ä½¿ç”¨åŸå­æ€§æ›¿æ¢æ¨¡å¼ï¼ˆå…ˆå†™å…¥ä¸´æ—¶ç›®å½•ï¼Œå®ŒæˆååŸå­æ€§æ›¿æ¢ï¼‰")

            # åˆå§‹åŒ–ç»Ÿè®¡ä¿¡æ¯
            processed_count = 0
            saved_count = 0
            domain_stats = {}
            saved_files = []
            affected_domains = set()  # è®°å½•å—å½±å“çš„domain

            # åˆ†é¡µè·å–è§†å›¾è¡¨åˆ—è¡¨
            page = 1
            total_items = None

            while True:
                if verbose or page == 1:
                    logger.info(f"ğŸ“¡ æ­£åœ¨è·å–è§†å›¾è¡¨åˆ—è¡¨ï¼ˆç¬¬{page}é¡µï¼‰...")

                # è·å–å½“å‰é¡µæ•°æ®
                result = await self._get_view_table_list(page, page_size)

                # æ£€æŸ¥å“åº”çŠ¶æ€
                if result.get("status_code") == -1:
                    logger.error(f"è·å–è§†å›¾è¡¨åˆ—è¡¨å¤±è´¥: {result.get('status_msg')}")
                    break

                # æå–æ•°æ®
                # resultç»“æ„å¯èƒ½æ˜¯ï¼š
                # 1. listæ ¼å¼: {"status_code": 0, "data": [...], "total": -1}
                # 2. dictæ ¼å¼: {"status_code": 0, "data": {"items": [...], "total": 100}}
                data = result.get("data", {})
                result_total = result.get("total", 0)  # è·å–å¤–å±‚çš„totalå­—æ®µ

                # è°ƒè¯•è¾“å‡ºï¼šæ£€æŸ¥dataç±»å‹
                if verbose:
                    logger.debug(f"dataç±»å‹: {type(data)}, result.total={result_total}")

                # å¤„ç†dataå¯èƒ½æ˜¯listçš„æƒ…å†µ
                if isinstance(data, list):
                    items = data
                    # å¦‚æœå¤–å±‚æœ‰totalå­—æ®µï¼Œä¼˜å…ˆä½¿ç”¨å¤–å±‚çš„total
                    total = result_total if result_total != 0 else len(data)
                elif isinstance(data, dict):
                    items = data.get("items", [])
                    # dictæ ¼å¼ä¼˜å…ˆä½¿ç”¨å†…å±‚çš„total
                    total = data.get("total", result_total)
                else:
                    logger.error(f"æœªçŸ¥çš„dataæ ¼å¼: {type(data)}")
                    break

                if total_items is None:
                    if total == -1:
                        logger.info(f"ğŸ“Š APIæœªè¿”å›æ€»æ•°ï¼Œå°†æŒç»­åˆ†é¡µç›´åˆ°æ— æ•°æ®")
                        total_items = -1
                    else:
                        total_items = total
                        logger.info(f"ğŸ“Š å…±æœ‰ {total_items} ä¸ªè§†å›¾è¡¨éœ€è¦å¤„ç†")

                if not items:
                    logger.info(f"ğŸ“„ ç¬¬{page}é¡µæ— æ•°æ®ï¼Œå¯¼å‡ºå®Œæˆ")
                    break

                # å¤„ç†å½“å‰é¡µçš„è§†å›¾è¡¨
                for item in items:
                    try:
                        # æå–domainå’ŒtableName
                        domain = item.get("domain", "")
                        table_name = item.get("tableName", "")

                        if not table_name:
                            logger.warning(f"è§†å›¾è¡¨ç¼ºå°‘tableNameå­—æ®µï¼Œè·³è¿‡: {item}")
                            continue

                        # æ˜ å°„domainåˆ°ç®€ç§°
                        domain_short = self.DOMAIN_MAPPING.get(domain, None)

                        if not domain_short:
                            if verbose:
                                logger.warning(f"æœªçŸ¥çš„domain: {domain}ï¼Œä½¿ç”¨'unknown'")
                            domain_short = "unknown"

                        # Domainè¿‡æ»¤
                        if domains and domain_short not in domains:
                            continue

                        processed_count += 1

                        # æ„å»ºYAMLæ•°æ®
                        yaml_data = self._build_yaml_data(item, domain_short)

                        # æ·»åŠ æ–‡ä»¶è·¯å¾„ä¿¡æ¯
                        filename = sanitize_filename(table_name)
                        yaml_data["_file_info"] = {
                            "filename": f"{filename}.yaml",
                            "business_line": domain_short,  # ä½¿ç”¨domain_shortä½œä¸ºä¸šåŠ¡çº¿
                            "category": None,  # fin_data_analysisç±»å‹ä¸ä½¿ç”¨categoryå­ç›®å½•
                            "use_temp_dir": use_atomic_replace
                        }

                        # æ›´æ–°domainç»Ÿè®¡
                        domain_stats[domain_short] = domain_stats.get(domain_short, 0) + 1
                        affected_domains.add(domain_short)

                        # ä¿å­˜æ–‡ä»¶
                        if not dry_run:
                            file_path = await self._save_single_file_async(yaml_data, use_atomic_replace)
                            if file_path:
                                saved_files.append(file_path)
                                saved_count += 1

                        if verbose and processed_count % 50 == 0:
                            logger.info(f"ğŸ“Š å·²å¤„ç†: {processed_count} ä¸ªè§†å›¾è¡¨")

                    except Exception as e:
                        logger.error(f"å¤„ç†è§†å›¾è¡¨å¤±è´¥: {item.get('tableName', 'unknown')}, é”™è¯¯: {str(e)}")
                        continue

                # æ£€æŸ¥æ˜¯å¦è¿˜æœ‰ä¸‹ä¸€é¡µ
                # å¦‚æœtotal=-1ï¼ˆæœªçŸ¥æ€»æ•°ï¼‰ï¼Œåˆ™ç»§ç»­è¯·æ±‚ä¸‹ä¸€é¡µï¼Œç›´åˆ°è¿”å›ç©ºæ•°ç»„
                # å¦‚æœtotalå·²çŸ¥ï¼Œåˆ™æ£€æŸ¥æ˜¯å¦å·²å¤„ç†å®Œæ‰€æœ‰æ•°æ®
                if total_items != -1 and processed_count >= total_items:
                    logger.info(f"âœ… å·²å¤„ç†æ‰€æœ‰ {processed_count} ä¸ªè§†å›¾è¡¨")
                    break

                page += 1

            # åŸå­æ€§æ›¿æ¢ï¼šå°†ä¸´æ—¶ç›®å½•æ›¿æ¢ä¸ºæ­£å¼ç›®å½•
            if use_atomic_replace and not dry_run and affected_domains:
                logger.info("\nğŸ”„ å¼€å§‹åŸå­æ€§æ›¿æ¢ç›®å½•...")
                replace_success_count = 0
                replace_fail_count = 0

                for domain_short in sorted(affected_domains):
                    try:
                        success = self.file_manager.atomic_replace_category_dir(
                            business_line=domain_short,
                            category=None  # fin_data_analysisç±»å‹ä¸ä½¿ç”¨categoryå­ç›®å½•
                        )
                        if success:
                            replace_success_count += 1
                        else:
                            replace_fail_count += 1
                    except Exception as e:
                        logger.error(f"åŸå­æ€§æ›¿æ¢å¤±è´¥ {domain_short}/fin_view: {e}")
                        replace_fail_count += 1

                logger.info(f"âœ… åŸå­æ€§æ›¿æ¢å®Œæˆ: æˆåŠŸ {replace_success_count} ä¸ªï¼Œå¤±è´¥ {replace_fail_count} ä¸ª")

                if replace_fail_count > 0:
                    logger.warning("éƒ¨åˆ†domainçš„åŸå­æ€§æ›¿æ¢å¤±è´¥ï¼Œè¯·æ£€æŸ¥æ—¥å¿—")

            # æ˜¾ç¤ºæœ€ç»ˆç»Ÿè®¡
            end_time = datetime.now()
            duration = (end_time - start_time).total_seconds()

            logger.info("\n" + "=" * 80)
            logger.info("âœ… é‡‘èæŒ‡æ ‡è§†å›¾è¡¨å¯¼å‡ºå®Œæˆ!")
            logger.info(f"ğŸ“Š å¤„ç†è§†å›¾è¡¨: {processed_count} ä¸ª")
            logger.info(f"ğŸ’¾ ä¿å­˜æ–‡ä»¶: {saved_count} ä¸ª")
            logger.info(f"ğŸ“‚ è¾“å‡ºç›®å½•: {self.output_dir}")
            logger.info(f"â±ï¸  è€—æ—¶: {duration:.2f} ç§’")

            if verbose and domain_stats:
                logger.info("\nğŸ“ Domainåˆ†å¸ƒ:")
                for domain_short, count in sorted(domain_stats.items()):
                    logger.info(f"  - {domain_short}: {count} ä¸ª")

            logger.info("=" * 80)
            return True

        except Exception as e:
            logger.error(f"é‡‘èæŒ‡æ ‡è§†å›¾è¡¨å¯¼å‡ºè¿‡ç¨‹å¼‚å¸¸: {str(e)}", exc_info=True)
            return False

        finally:
            await self.https_client.close()

    async def _get_view_table_list(self, page: int, page_size: int) -> Dict[str, Any]:
        """
        è·å–è§†å›¾è¡¨åˆ—è¡¨

        Args:
            page: é¡µç 
            page_size: æ¯é¡µå¤§å°

        Returns:
            è§†å›¾è¡¨åˆ—è¡¨
        """
        try:
            result = await self.https_client.get_view_table_list(page, page_size)
            return result
        except Exception as e:
            logger.error(f"è·å–è§†å›¾è¡¨åˆ—è¡¨å¤±è´¥: {str(e)}")
            raise

    def _build_yaml_data(self, item: Dict[str, Any], domain_short: str) -> Dict[str, Any]:
        """
        æ„å»ºYAMLæ•°æ®

        Args:
            item: è§†å›¾è¡¨æ•°æ®
            domain_short: Domainç®€ç§°

        Returns:
            YAMLæ•°æ®
        """
        import json

        # æå–åŸºç¡€å­—æ®µ
        table_name = item.get("tableName", "")
        domain = item.get("domain", "")

        # æå–å­—æ®µåˆ—è¡¨ï¼ˆå¦‚æœæœ‰ï¼‰
        columns = item.get("columns", [])

        # å¦‚æœcolumnsæ˜¯å­—ç¬¦ä¸²ï¼Œå°è¯•è§£æä¸ºJSON
        if isinstance(columns, str):
            try:
                columns = json.loads(columns)
            except:
                columns = []

        # æ ¼å¼åŒ–columnsä¸ºJSONå­—ç¬¦ä¸²ï¼ˆä¿ç•™åŸå§‹å­—æ®µï¼Œä¸åšç®€åŒ–å¤„ç†ï¼‰
        if columns and isinstance(columns, list):
            # ä½¿ç”¨json.dumpsæ ¼å¼åŒ–ä¸ºå¤šè¡ŒJSONå­—ç¬¦ä¸²ï¼Œä¿ç•™APIè¿”å›çš„æ‰€æœ‰å­—æ®µ
            json_str = json.dumps(columns, indent=2, ensure_ascii=False)
            # ä½¿ç”¨ç‰¹æ®Šæ ‡è®°ï¼Œåç»­å¤„ç†æ—¶è½¬æ¢ä¸ºliteral block scalar
            columns_display = f"__LITERAL_BLOCK_START__\n{json_str}\n__LITERAL_BLOCK_END__"
        else:
            columns_display = "[]"

        # æ„å»ºYAMLæ•°æ®ï¼ˆä¿ç•™APIè¿”å›çš„æ‰€æœ‰å­—æ®µï¼‰
        # å…ˆæ·»åŠ tableIdï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        yaml_data = {}
        if "tableId" in item:
            yaml_data["tableId"] = item["tableId"]

        # å†æ·»åŠ tableNameå’Œdomain
        yaml_data["tableName"] = table_name
        yaml_data["domain"] = domain

        # æ·»åŠ å…¶ä»–å­—æ®µï¼ˆæ’é™¤å·²å¤„ç†çš„å­—æ®µï¼‰
        for key, value in item.items():
            if key not in ["tableId", "tableName", "domain", "columns"]:
                yaml_data[key] = value

        # æœ€åæ·»åŠ columnså­—æ®µ
        yaml_data["columns"] = columns_display

        # æ·»åŠ å­—æ®µæ³¨é‡Š
        yaml_data["_field_comments"] = {
            "tableId": "è§†å›¾è¡¨ID",
            "tableName": "è§†å›¾è¡¨åç§°",
            "domain": "æ‰€å±é¢†åŸŸ",
            "columns": "å­—æ®µåˆ—è¡¨"
        }

        return yaml_data

    async def _save_single_file_async(self, data: Dict[str, Any], use_temp_dir: bool = False) -> Optional[str]:
        """
        å¼‚æ­¥ä¿å­˜å•ä¸ªæ–‡ä»¶

        Args:
            data: è§†å›¾è¡¨æ•°æ®
            use_temp_dir: æ˜¯å¦ä½¿ç”¨ä¸´æ—¶ç›®å½•ï¼ˆç”¨äºåŸå­æ€§æ›¿æ¢ï¼‰

        Returns:
            ä¿å­˜çš„æ–‡ä»¶è·¯å¾„ï¼Œå¤±è´¥è¿”å›None
        """
        try:
            file_info = data.get("_file_info")
            if not file_info:
                return None

            filename = file_info["filename"]
            business_line = file_info["business_line"]
            category = file_info["category"]

            # æ ¹æ®æ˜¯å¦ä½¿ç”¨ä¸´æ—¶ç›®å½•é€‰æ‹©ä¸åŒçš„è·¯å¾„ç”Ÿæˆæ–¹æ³•
            if use_temp_dir:
                file_path = self.file_manager.generate_file_path_in_temp(filename, business_line, category)
            else:
                file_path = self.file_manager.generate_file_path(filename, business_line, category)

            # åœ¨å¼‚æ­¥ç¯å¢ƒä¸­ä¿å­˜æ–‡ä»¶
            loop = asyncio.get_event_loop()
            success = await loop.run_in_executor(
                None, self.file_manager.save_yaml_file, data, file_path
            )

            if success:
                return str(file_path)

        except Exception as e:
            logger.error(f"å¼‚æ­¥ä¿å­˜æ–‡ä»¶å¤±è´¥: {str(e)}")

        return None
